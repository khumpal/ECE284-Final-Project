{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 50 ic-slices out of 64 ic-slices per output channel (78.1% pruned)\n",
      "Pruning 50 ic-slices out of 64 ic-slices per output channel (78.1% pruned)\n",
      "Pruning 100 ic-slices out of 128 ic-slices per output channel (78.1% pruned)\n",
      "Pruning 100 ic-slices out of 128 ic-slices per output channel (78.1% pruned)\n",
      "Pruning 200 ic-slices out of 256 ic-slices per output channel (78.1% pruned)\n",
      "Pruning 200 ic-slices out of 256 ic-slices per output channel (78.1% pruned)\n",
      "Pruning 200 ic-slices out of 256 ic-slices per output channel (78.1% pruned)\n",
      "Pruning 399 ic-slices out of 512 ic-slices per output channel (77.9% pruned)\n",
      "Pruning 399 ic-slices out of 512 ic-slices per output channel (77.9% pruned)\n",
      "Pruning 399 ic-slices out of 512 ic-slices per output channel (77.9% pruned)\n",
      "Pruning 399 ic-slices out of 512 ic-slices per output channel (77.9% pruned)\n",
      "Pruning 399 ic-slices out of 512 ic-slices per output channel (77.9% pruned)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124282/2264729797.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f\"result/VGG16_os_iter_prune_0.78/model_best.pth.tar\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "from models import *\n",
    "from models.prune_util import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "global best_prec\n",
    "\n",
    "batch_size = 64\n",
    "model_name = f\"VGG16_os_iter_prune_0.78_q\"\n",
    "fdir = 'result/' + model_name\n",
    "model = VGG16()\n",
    "os_prune_vgg16(model, 0.78)\n",
    "checkpoint = torch.load(f\"result/VGG16_os_iter_prune_0.78/model_best.pth.tar\")\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.cuda()\n",
    "\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))      \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [150, 225]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "def train_model(model, fdir, criterion, optimizer, epochs): \n",
    "    os.makedirs(fdir, exist_ok=True)\n",
    "\n",
    "    best_prec = 0\n",
    "\n",
    "    #model = nn.DataParallel(model).cuda()\n",
    "    model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    #cudnn.benchmark = True\n",
    "            \n",
    "\n",
    "    for epoch in range(0, epochs):\n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "        train(trainloader, model, criterion, optimizer, epoch)\n",
    "        \n",
    "        # evaluate on test set\n",
    "        print(\"Validation starts\")\n",
    "        prec = validate(testloader, model, criterion)\n",
    "\n",
    "        # remember best precision and save checkpoint\n",
    "        is_best = prec > best_prec\n",
    "        best_prec = max(prec,best_prec)\n",
    "        print('best acc: {:1f}'.format(best_prec))\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec': best_prec,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, fdir)\n",
    "\n",
    "def val_model(model): \n",
    "\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in testloader:\n",
    "            data, target = data.to(device), target.to(device) # loading to GPU\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(testloader.dataset)\n",
    "\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            correct, len(testloader.dataset),\n",
    "            100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9041/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 1139/10000 (11%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "quantize_pruned(model)\n",
    "\n",
    "val_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/782]\tTime 1.061 (1.061)\tData 0.017 (0.017)\tLoss 0.0232 (0.0232)\tPrec 100.000% (100.000%)\n",
      "Epoch: [0][100/782]\tTime 0.052 (0.078)\tData 0.012 (0.013)\tLoss 0.1032 (0.0674)\tPrec 93.750% (97.525%)\n",
      "Epoch: [0][200/782]\tTime 0.067 (0.073)\tData 0.012 (0.013)\tLoss 0.0320 (0.0678)\tPrec 98.438% (97.536%)\n",
      "Epoch: [0][300/782]\tTime 0.066 (0.071)\tData 0.013 (0.013)\tLoss 0.2043 (0.0673)\tPrec 95.312% (97.612%)\n",
      "Epoch: [0][400/782]\tTime 0.079 (0.070)\tData 0.012 (0.013)\tLoss 0.1344 (0.0655)\tPrec 95.312% (97.685%)\n",
      "Epoch: [0][500/782]\tTime 0.067 (0.069)\tData 0.012 (0.013)\tLoss 0.0308 (0.0641)\tPrec 98.438% (97.767%)\n",
      "Epoch: [0][600/782]\tTime 0.067 (0.069)\tData 0.014 (0.013)\tLoss 0.0602 (0.0651)\tPrec 98.438% (97.775%)\n",
      "Epoch: [0][700/782]\tTime 0.066 (0.069)\tData 0.012 (0.013)\tLoss 0.1622 (0.0639)\tPrec 93.750% (97.782%)\n",
      "Validation starts\n",
      "Test: [0/157]\tTime 0.032 (0.032)\tLoss 0.4741 (0.4741)\tPrec 85.938% (85.938%)\n",
      "Test: [100/157]\tTime 0.031 (0.031)\tLoss 0.4337 (0.4838)\tPrec 85.938% (89.604%)\n",
      " * Prec 90.000% \n",
      "best acc: 90.000000\n",
      "Epoch: [1][0/782]\tTime 0.056 (0.056)\tData 0.018 (0.018)\tLoss 0.0427 (0.0427)\tPrec 98.438% (98.438%)\n",
      "Epoch: [1][100/782]\tTime 0.067 (0.067)\tData 0.012 (0.013)\tLoss 0.1348 (0.0591)\tPrec 93.750% (97.927%)\n",
      "Epoch: [1][200/782]\tTime 0.054 (0.067)\tData 0.012 (0.013)\tLoss 0.0260 (0.0599)\tPrec 98.438% (97.932%)\n",
      "Epoch: [1][300/782]\tTime 0.068 (0.067)\tData 0.012 (0.013)\tLoss 0.1066 (0.0535)\tPrec 92.188% (98.136%)\n",
      "Epoch: [1][400/782]\tTime 0.065 (0.067)\tData 0.012 (0.013)\tLoss 0.0582 (0.0546)\tPrec 98.438% (98.071%)\n",
      "Epoch: [1][500/782]\tTime 0.068 (0.067)\tData 0.012 (0.013)\tLoss 0.0248 (0.0529)\tPrec 98.438% (98.144%)\n",
      "Epoch: [1][600/782]\tTime 0.070 (0.067)\tData 0.012 (0.013)\tLoss 0.1037 (0.0534)\tPrec 98.438% (98.154%)\n",
      "Epoch: [1][700/782]\tTime 0.066 (0.067)\tData 0.012 (0.013)\tLoss 0.1452 (0.0539)\tPrec 95.312% (98.143%)\n",
      "Validation starts\n",
      "Test: [0/157]\tTime 0.043 (0.043)\tLoss 0.7697 (0.7697)\tPrec 84.375% (84.375%)\n",
      "Test: [100/157]\tTime 0.031 (0.032)\tLoss 0.5551 (0.4575)\tPrec 85.938% (89.356%)\n",
      " * Prec 89.560% \n",
      "best acc: 90.000000\n",
      "Epoch: [2][0/782]\tTime 0.063 (0.063)\tData 0.028 (0.028)\tLoss 0.0944 (0.0944)\tPrec 95.312% (95.312%)\n",
      "Epoch: [2][100/782]\tTime 0.066 (0.067)\tData 0.013 (0.013)\tLoss 0.0169 (0.0522)\tPrec 100.000% (98.066%)\n",
      "Epoch: [2][200/782]\tTime 0.068 (0.067)\tData 0.012 (0.013)\tLoss 0.1069 (0.0493)\tPrec 93.750% (98.189%)\n",
      "Epoch: [2][300/782]\tTime 0.067 (0.067)\tData 0.012 (0.013)\tLoss 0.0023 (0.0490)\tPrec 100.000% (98.225%)\n",
      "Epoch: [2][400/782]\tTime 0.066 (0.067)\tData 0.012 (0.013)\tLoss 0.0413 (0.0502)\tPrec 98.438% (98.110%)\n",
      "Epoch: [2][500/782]\tTime 0.067 (0.067)\tData 0.012 (0.013)\tLoss 0.0276 (0.0512)\tPrec 98.438% (98.123%)\n",
      "Epoch: [2][600/782]\tTime 0.066 (0.067)\tData 0.013 (0.013)\tLoss 0.0590 (0.0515)\tPrec 98.438% (98.131%)\n",
      "Epoch: [2][700/782]\tTime 0.067 (0.067)\tData 0.012 (0.013)\tLoss 0.2138 (0.0510)\tPrec 92.188% (98.152%)\n",
      "Validation starts\n",
      "Test: [0/157]\tTime 0.041 (0.041)\tLoss 0.3580 (0.3580)\tPrec 87.500% (87.500%)\n",
      "Test: [100/157]\tTime 0.032 (0.033)\tLoss 0.7504 (0.4644)\tPrec 85.938% (89.960%)\n",
      " * Prec 90.050% \n",
      "best acc: 90.050000\n",
      "Epoch: [3][0/782]\tTime 0.062 (0.062)\tData 0.025 (0.025)\tLoss 0.0217 (0.0217)\tPrec 100.000% (100.000%)\n",
      "Epoch: [3][100/782]\tTime 0.068 (0.067)\tData 0.013 (0.013)\tLoss 0.0557 (0.0507)\tPrec 98.438% (98.097%)\n",
      "Epoch: [3][200/782]\tTime 0.067 (0.067)\tData 0.013 (0.014)\tLoss 0.0332 (0.0530)\tPrec 100.000% (98.103%)\n",
      "Epoch: [3][300/782]\tTime 0.081 (0.067)\tData 0.012 (0.014)\tLoss 0.0028 (0.0511)\tPrec 100.000% (98.168%)\n",
      "Epoch: [3][400/782]\tTime 0.067 (0.067)\tData 0.013 (0.014)\tLoss 0.0245 (0.0511)\tPrec 98.438% (98.173%)\n",
      "Epoch: [3][500/782]\tTime 0.068 (0.067)\tData 0.013 (0.014)\tLoss 0.0816 (0.0527)\tPrec 93.750% (98.154%)\n",
      "Epoch: [3][600/782]\tTime 0.067 (0.067)\tData 0.014 (0.014)\tLoss 0.1388 (0.0521)\tPrec 95.312% (98.162%)\n",
      "Epoch: [3][700/782]\tTime 0.067 (0.067)\tData 0.012 (0.014)\tLoss 0.0185 (0.0523)\tPrec 98.438% (98.152%)\n",
      "Validation starts\n",
      "Test: [0/157]\tTime 0.043 (0.043)\tLoss 0.4881 (0.4881)\tPrec 87.500% (87.500%)\n",
      "Test: [100/157]\tTime 0.032 (0.032)\tLoss 0.7169 (0.4667)\tPrec 89.062% (89.882%)\n",
      " * Prec 90.100% \n",
      "best acc: 90.100000\n",
      "Epoch: [4][0/782]\tTime 0.070 (0.070)\tData 0.033 (0.033)\tLoss 0.0192 (0.0192)\tPrec 98.438% (98.438%)\n",
      "Epoch: [4][100/782]\tTime 0.066 (0.067)\tData 0.013 (0.015)\tLoss 0.0730 (0.0444)\tPrec 96.875% (98.484%)\n",
      "Epoch: [4][200/782]\tTime 0.067 (0.067)\tData 0.027 (0.015)\tLoss 0.0158 (0.0468)\tPrec 100.000% (98.391%)\n",
      "Epoch: [4][300/782]\tTime 0.067 (0.067)\tData 0.012 (0.015)\tLoss 0.0088 (0.0486)\tPrec 100.000% (98.323%)\n",
      "Epoch: [4][400/782]\tTime 0.068 (0.067)\tData 0.012 (0.015)\tLoss 0.0401 (0.0503)\tPrec 98.438% (98.258%)\n",
      "Epoch: [4][500/782]\tTime 0.078 (0.067)\tData 0.012 (0.015)\tLoss 0.0319 (0.0497)\tPrec 98.438% (98.272%)\n",
      "Epoch: [4][600/782]\tTime 0.067 (0.067)\tData 0.012 (0.015)\tLoss 0.0689 (0.0502)\tPrec 98.438% (98.274%)\n",
      "Epoch: [4][700/782]\tTime 0.066 (0.067)\tData 0.012 (0.015)\tLoss 0.0044 (0.0508)\tPrec 100.000% (98.257%)\n",
      "Validation starts\n",
      "Test: [0/157]\tTime 0.043 (0.043)\tLoss 0.4924 (0.4924)\tPrec 85.938% (85.938%)\n",
      "Test: [100/157]\tTime 0.032 (0.032)\tLoss 0.4847 (0.4919)\tPrec 87.500% (89.542%)\n",
      " * Prec 89.790% \n",
      "best acc: 90.100000\n",
      "Epoch: [5][0/782]\tTime 0.050 (0.050)\tData 0.016 (0.016)\tLoss 0.0252 (0.0252)\tPrec 100.000% (100.000%)\n",
      "Epoch: [5][100/782]\tTime 0.068 (0.067)\tData 0.024 (0.014)\tLoss 0.0408 (0.0535)\tPrec 98.438% (98.066%)\n",
      "Epoch: [5][200/782]\tTime 0.067 (0.067)\tData 0.015 (0.015)\tLoss 0.0111 (0.0485)\tPrec 100.000% (98.282%)\n",
      "Epoch: [5][300/782]\tTime 0.067 (0.067)\tData 0.015 (0.015)\tLoss 0.0039 (0.0476)\tPrec 100.000% (98.344%)\n",
      "Epoch: [5][400/782]\tTime 0.067 (0.067)\tData 0.013 (0.015)\tLoss 0.0640 (0.0492)\tPrec 98.438% (98.317%)\n",
      "Epoch: [5][500/782]\tTime 0.066 (0.067)\tData 0.027 (0.015)\tLoss 0.0207 (0.0512)\tPrec 98.438% (98.272%)\n",
      "Epoch: [5][600/782]\tTime 0.066 (0.067)\tData 0.027 (0.015)\tLoss 0.0439 (0.0529)\tPrec 98.438% (98.204%)\n",
      "Epoch: [5][700/782]\tTime 0.067 (0.067)\tData 0.025 (0.015)\tLoss 0.0183 (0.0528)\tPrec 100.000% (98.206%)\n",
      "Validation starts\n",
      "Test: [0/157]\tTime 0.042 (0.042)\tLoss 0.4042 (0.4042)\tPrec 90.625% (90.625%)\n",
      "Test: [100/157]\tTime 0.033 (0.032)\tLoss 0.6283 (0.4695)\tPrec 85.938% (90.006%)\n",
      " * Prec 90.140% \n",
      "best acc: 90.140000\n",
      "Epoch: [6][0/782]\tTime 0.052 (0.052)\tData 0.018 (0.018)\tLoss 0.0168 (0.0168)\tPrec 100.000% (100.000%)\n",
      "Epoch: [6][100/782]\tTime 0.067 (0.067)\tData 0.012 (0.015)\tLoss 0.0892 (0.0518)\tPrec 98.438% (98.205%)\n",
      "Epoch: [6][200/782]\tTime 0.067 (0.067)\tData 0.017 (0.015)\tLoss 0.0668 (0.0504)\tPrec 98.438% (98.290%)\n",
      "Epoch: [6][300/782]\tTime 0.067 (0.067)\tData 0.012 (0.015)\tLoss 0.0535 (0.0504)\tPrec 95.312% (98.271%)\n",
      "Epoch: [6][400/782]\tTime 0.067 (0.067)\tData 0.014 (0.015)\tLoss 0.0372 (0.0518)\tPrec 98.438% (98.247%)\n",
      "Epoch: [6][500/782]\tTime 0.066 (0.067)\tData 0.012 (0.015)\tLoss 0.0285 (0.0498)\tPrec 98.438% (98.307%)\n",
      "Epoch: [6][600/782]\tTime 0.066 (0.067)\tData 0.012 (0.015)\tLoss 0.0319 (0.0495)\tPrec 98.438% (98.302%)\n",
      "Epoch: [6][700/782]\tTime 0.066 (0.067)\tData 0.013 (0.015)\tLoss 0.0414 (0.0492)\tPrec 98.438% (98.304%)\n",
      "Validation starts\n",
      "Test: [0/157]\tTime 0.041 (0.041)\tLoss 0.4478 (0.4478)\tPrec 87.500% (87.500%)\n",
      "Test: [100/157]\tTime 0.031 (0.031)\tLoss 0.8007 (0.4519)\tPrec 89.062% (89.991%)\n",
      " * Prec 90.100% \n",
      "best acc: 90.140000\n",
      "Epoch: [7][0/782]\tTime 0.076 (0.076)\tData 0.023 (0.023)\tLoss 0.0259 (0.0259)\tPrec 100.000% (100.000%)\n",
      "Epoch: [7][100/782]\tTime 0.066 (0.066)\tData 0.013 (0.015)\tLoss 0.0049 (0.0501)\tPrec 100.000% (98.329%)\n",
      "Epoch: [7][200/782]\tTime 0.051 (0.066)\tData 0.012 (0.014)\tLoss 0.0049 (0.0486)\tPrec 100.000% (98.235%)\n",
      "Epoch: [7][300/782]\tTime 0.066 (0.066)\tData 0.012 (0.013)\tLoss 0.0427 (0.0472)\tPrec 96.875% (98.328%)\n",
      "Epoch: [7][400/782]\tTime 0.064 (0.066)\tData 0.024 (0.013)\tLoss 0.0931 (0.0482)\tPrec 98.438% (98.282%)\n",
      "Epoch: [7][500/782]\tTime 0.066 (0.066)\tData 0.012 (0.013)\tLoss 0.0188 (0.0470)\tPrec 98.438% (98.338%)\n",
      "Epoch: [7][600/782]\tTime 0.067 (0.066)\tData 0.013 (0.013)\tLoss 0.0237 (0.0480)\tPrec 98.438% (98.313%)\n",
      "Epoch: [7][700/782]\tTime 0.066 (0.066)\tData 0.012 (0.013)\tLoss 0.0446 (0.0491)\tPrec 98.438% (98.281%)\n",
      "Validation starts\n",
      "Test: [0/157]\tTime 0.042 (0.042)\tLoss 0.4573 (0.4573)\tPrec 89.062% (89.062%)\n",
      "Test: [100/157]\tTime 0.032 (0.032)\tLoss 0.6790 (0.4788)\tPrec 87.500% (89.604%)\n",
      " * Prec 89.610% \n",
      "best acc: 90.140000\n",
      "Epoch: [8][0/782]\tTime 0.058 (0.058)\tData 0.023 (0.023)\tLoss 0.0459 (0.0459)\tPrec 96.875% (96.875%)\n",
      "Epoch: [8][100/782]\tTime 0.076 (0.067)\tData 0.012 (0.015)\tLoss 0.0128 (0.0421)\tPrec 100.000% (98.608%)\n",
      "Epoch: [8][200/782]\tTime 0.066 (0.067)\tData 0.013 (0.015)\tLoss 0.0052 (0.0462)\tPrec 100.000% (98.539%)\n",
      "Epoch: [8][300/782]\tTime 0.067 (0.067)\tData 0.018 (0.015)\tLoss 0.0640 (0.0459)\tPrec 98.438% (98.495%)\n",
      "Epoch: [8][400/782]\tTime 0.067 (0.067)\tData 0.012 (0.015)\tLoss 0.0631 (0.0476)\tPrec 98.438% (98.387%)\n",
      "Epoch: [8][500/782]\tTime 0.067 (0.067)\tData 0.012 (0.015)\tLoss 0.0343 (0.0487)\tPrec 98.438% (98.288%)\n",
      "Epoch: [8][600/782]\tTime 0.055 (0.067)\tData 0.021 (0.015)\tLoss 0.0184 (0.0479)\tPrec 100.000% (98.323%)\n",
      "Epoch: [8][700/782]\tTime 0.051 (0.067)\tData 0.016 (0.015)\tLoss 0.1351 (0.0491)\tPrec 95.312% (98.284%)\n",
      "Validation starts\n",
      "Test: [0/157]\tTime 0.043 (0.043)\tLoss 0.5447 (0.5447)\tPrec 89.062% (89.062%)\n",
      "Test: [100/157]\tTime 0.031 (0.031)\tLoss 0.6002 (0.4433)\tPrec 87.500% (89.944%)\n",
      " * Prec 90.340% \n",
      "best acc: 90.340000\n",
      "Epoch: [9][0/782]\tTime 0.056 (0.056)\tData 0.021 (0.021)\tLoss 0.0366 (0.0366)\tPrec 98.438% (98.438%)\n",
      "Epoch: [9][100/782]\tTime 0.067 (0.067)\tData 0.012 (0.014)\tLoss 0.0583 (0.0482)\tPrec 98.438% (98.267%)\n",
      "Epoch: [9][200/782]\tTime 0.060 (0.067)\tData 0.012 (0.015)\tLoss 0.1057 (0.0465)\tPrec 95.312% (98.204%)\n",
      "Epoch: [9][300/782]\tTime 0.066 (0.067)\tData 0.015 (0.015)\tLoss 0.0446 (0.0471)\tPrec 96.875% (98.199%)\n",
      "Epoch: [9][400/782]\tTime 0.066 (0.067)\tData 0.012 (0.015)\tLoss 0.0342 (0.0468)\tPrec 96.875% (98.258%)\n",
      "Epoch: [9][500/782]\tTime 0.067 (0.067)\tData 0.012 (0.014)\tLoss 0.0432 (0.0471)\tPrec 96.875% (98.263%)\n",
      "Epoch: [9][600/782]\tTime 0.067 (0.067)\tData 0.012 (0.014)\tLoss 0.0861 (0.0481)\tPrec 95.312% (98.237%)\n",
      "Epoch: [9][700/782]\tTime 0.067 (0.067)\tData 0.012 (0.014)\tLoss 0.0671 (0.0476)\tPrec 96.875% (98.264%)\n",
      "Validation starts\n",
      "Test: [0/157]\tTime 0.033 (0.033)\tLoss 0.3820 (0.3820)\tPrec 87.500% (87.500%)\n",
      "Test: [100/157]\tTime 0.032 (0.031)\tLoss 0.6876 (0.4366)\tPrec 85.938% (90.068%)\n",
      " * Prec 90.270% \n",
      "best acc: 90.340000\n",
      "Epoch: [10][0/782]\tTime 0.058 (0.058)\tData 0.024 (0.024)\tLoss 0.0387 (0.0387)\tPrec 98.438% (98.438%)\n",
      "Epoch: [10][100/782]\tTime 0.066 (0.067)\tData 0.012 (0.013)\tLoss 0.0452 (0.0500)\tPrec 96.875% (98.329%)\n",
      "Epoch: [10][200/782]\tTime 0.066 (0.067)\tData 0.012 (0.013)\tLoss 0.0435 (0.0466)\tPrec 98.438% (98.500%)\n",
      "Epoch: [10][300/782]\tTime 0.067 (0.067)\tData 0.012 (0.013)\tLoss 0.0013 (0.0446)\tPrec 100.000% (98.562%)\n",
      "Epoch: [10][400/782]\tTime 0.066 (0.067)\tData 0.012 (0.013)\tLoss 0.0402 (0.0465)\tPrec 98.438% (98.484%)\n",
      "Epoch: [10][500/782]\tTime 0.066 (0.067)\tData 0.012 (0.013)\tLoss 0.0211 (0.0461)\tPrec 100.000% (98.481%)\n",
      "Epoch: [10][600/782]\tTime 0.067 (0.067)\tData 0.012 (0.012)\tLoss 0.0309 (0.0460)\tPrec 98.438% (98.466%)\n",
      "Epoch: [10][700/782]\tTime 0.067 (0.067)\tData 0.012 (0.012)\tLoss 0.0069 (0.0457)\tPrec 100.000% (98.431%)\n",
      "Validation starts\n",
      "Test: [0/157]\tTime 0.042 (0.042)\tLoss 0.3470 (0.3470)\tPrec 87.500% (87.500%)\n",
      "Test: [100/157]\tTime 0.031 (0.031)\tLoss 0.6924 (0.4424)\tPrec 87.500% (90.022%)\n",
      " * Prec 90.320% \n",
      "best acc: 90.340000\n",
      "Epoch: [11][0/782]\tTime 0.072 (0.072)\tData 0.021 (0.021)\tLoss 0.0047 (0.0047)\tPrec 100.000% (100.000%)\n",
      "Epoch: [11][100/782]\tTime 0.066 (0.067)\tData 0.025 (0.014)\tLoss 0.0523 (0.0408)\tPrec 98.438% (98.422%)\n",
      "Epoch: [11][200/782]\tTime 0.066 (0.067)\tData 0.012 (0.014)\tLoss 0.0113 (0.0408)\tPrec 100.000% (98.507%)\n",
      "Epoch: [11][300/782]\tTime 0.068 (0.067)\tData 0.013 (0.015)\tLoss 0.0770 (0.0407)\tPrec 98.438% (98.536%)\n",
      "Epoch: [11][400/782]\tTime 0.075 (0.067)\tData 0.023 (0.015)\tLoss 0.0054 (0.0436)\tPrec 100.000% (98.426%)\n",
      "Epoch: [11][500/782]\tTime 0.067 (0.067)\tData 0.012 (0.015)\tLoss 0.0974 (0.0454)\tPrec 98.438% (98.375%)\n",
      "Epoch: [11][600/782]\tTime 0.067 (0.067)\tData 0.012 (0.014)\tLoss 0.0891 (0.0454)\tPrec 98.438% (98.375%)\n",
      "Epoch: [11][700/782]\tTime 0.077 (0.067)\tData 0.012 (0.014)\tLoss 0.0666 (0.0462)\tPrec 96.875% (98.328%)\n",
      "Validation starts\n",
      "Test: [0/157]\tTime 0.035 (0.035)\tLoss 0.6897 (0.6897)\tPrec 87.500% (87.500%)\n",
      "Test: [100/157]\tTime 0.031 (0.031)\tLoss 0.4341 (0.4959)\tPrec 90.625% (89.991%)\n",
      " * Prec 90.340% \n",
      "best acc: 90.340000\n",
      "Epoch: [12][0/782]\tTime 0.083 (0.083)\tData 0.027 (0.027)\tLoss 0.0502 (0.0502)\tPrec 96.875% (96.875%)\n",
      "Epoch: [12][100/782]\tTime 0.066 (0.067)\tData 0.012 (0.013)\tLoss 0.0065 (0.0430)\tPrec 100.000% (98.329%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 211\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, fdir, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, epochs):\n\u001b[1;32m    209\u001b[0m     adjust_learning_rate(optimizer, epoch)\n\u001b[0;32m--> 211\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# evaluate on test set\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation starts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 76\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(trainloader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     73\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     75\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 76\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# measure data loading time\u001b[39;49;00m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_time\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/conda-forge/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/micromamba/envs/conda-forge/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/micromamba/envs/conda-forge/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/micromamba/envs/conda-forge/lib/python3.12/site-packages/torchvision/datasets/cifar.py:119\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/micromamba/envs/conda-forge/lib/python3.12/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/micromamba/envs/conda-forge/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/conda-forge/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/conda-forge/lib/python3.12/site-packages/torchvision/transforms/transforms.py:671\u001b[0m, in \u001b[0;36mRandomCrop.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    669\u001b[0m     img \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(img, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode)\n\u001b[0;32m--> 671\u001b[0m _, height, width \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dimensions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;66;03m# pad the width if needed\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_if_needed \u001b[38;5;129;01mand\u001b[39;00m width \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m]:\n",
      "File \u001b[0;32m~/micromamba/envs/conda-forge/lib/python3.12/site-packages/torchvision/transforms/functional.py:76\u001b[0m, in \u001b[0;36mget_dimensions\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the dimensions of an image as [channels, height, width].\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    List[int]: The image dimensions.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[0;32m---> 76\u001b[0m     \u001b[43m_log_api_usage_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_dimensions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mget_dimensions(img)\n",
      "File \u001b[0;32m~/micromamba/envs/conda-forge/lib/python3.12/site-packages/torchvision/utils.py:643\u001b[0m, in \u001b[0;36m_log_api_usage_once\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, FunctionType):\n\u001b[1;32m    642\u001b[0m     name \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m--> 643\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_api_usage_once\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodule\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train_model(model, fdir, criterion, optimizer, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 50 ic-slices out of 64 ic-slices per output channel (78.1% pruned)\n",
      "Pruning 50 ic-slices out of 64 ic-slices per output channel (78.1% pruned)\n",
      "Pruning 100 ic-slices out of 128 ic-slices per output channel (78.1% pruned)\n",
      "Pruning 100 ic-slices out of 128 ic-slices per output channel (78.1% pruned)\n",
      "Pruning 200 ic-slices out of 256 ic-slices per output channel (78.1% pruned)\n",
      "Pruning 200 ic-slices out of 256 ic-slices per output channel (78.1% pruned)\n",
      "Pruning 200 ic-slices out of 256 ic-slices per output channel (78.1% pruned)\n",
      "Pruning 399 ic-slices out of 512 ic-slices per output channel (77.9% pruned)\n",
      "Pruning 399 ic-slices out of 512 ic-slices per output channel (77.9% pruned)\n",
      "Pruning 399 ic-slices out of 512 ic-slices per output channel (77.9% pruned)\n",
      "Pruning 399 ic-slices out of 512 ic-slices per output channel (77.9% pruned)\n",
      "Pruning 399 ic-slices out of 512 ic-slices per output channel (77.9% pruned)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124282/3884249786.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9034/10000 (90%)\n",
      "\n",
      "layer 3 sparsity: 0.766\n",
      "layer 7 sparsity: 0.766\n",
      "layer 10 sparsity: 0.773\n",
      "layer 14 sparsity: 0.773\n",
      "layer 17 sparsity: 0.770\n",
      "layer 20 sparsity: 0.770\n",
      "layer 24 sparsity: 0.770\n",
      "layer 27 sparsity: 0.779\n",
      "layer 30 sparsity: 0.779\n",
      "layer 34 sparsity: 0.779\n",
      "layer 37 sparsity: 0.779\n",
      "layer 40 sparsity: 0.779\n"
     ]
    }
   ],
   "source": [
    "model = VGG16()\n",
    "os_prune_vgg16(model, 0.78)\n",
    "quantize_pruned(model)\n",
    "\n",
    "PATH = f\"{fdir}/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.cuda()\n",
    "\n",
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []\n",
    "save_output = SaveOutput()\n",
    "model.features[40].register_forward_pre_hook(save_output)\n",
    "\n",
    "val_model(model)\n",
    "\n",
    "print_sparsity(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000, -1.4775, -1.4775],\n",
      "         [ 0.7387,  0.7387,  0.0000],\n",
      "         [ 0.0000,  0.7387,  0.0000]],\n",
      "\n",
      "        [[-0.0000,  0.0000,  0.7387],\n",
      "         [ 0.0000,  0.7387,  1.4775],\n",
      "         [ 0.7387,  0.7387,  0.7387]]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "l = model.features[40]\n",
    "a = [i for i in range(l.weight_mask.size(1)) if l.weight_mask[0,i].sum() > 0]\n",
    "print(l.weight_q[0,a[:2],:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0000, 0.0807],\n",
      "          [0.1303, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.5222, 0.3067],\n",
      "          [0.0775, 0.9398]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(save_output.outputs[0][0][:2,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight int: \n",
      "tensor([[ 0.0000, -2.0000, -2.0000],\n",
      "        [ 1.0000,  1.0000,  0.0000],\n",
      "        [ 0.0000,  1.0000,  0.0000]], device='cuda:0')\n",
      "Act int: \n",
      "tensor([[[[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1.],\n",
      "          [0., 2.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(f'Weight int: \\n{(model.features[40].weight_q.data / (model.features[40].weight_quant.wgt_alpha.data.item()/(2**(4-1)-1)))[0,a[0]]}')\n",
    "x = save_output.outputs[0][0]\n",
    "x_alpha = model.features[40].act_alpha.data.item()\n",
    "x_delta = x_alpha / (2**(4)-1)\n",
    "act_q = act_quantization(4)\n",
    "x_q = act_q(x, x_alpha)\n",
    "print(f'Act int: \\n{(x_q/x_delta)[:2,:2]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
